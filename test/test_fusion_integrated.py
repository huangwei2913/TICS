import torch
import torch.nn as nn
import os
import sys
from typing import List, Dict

# -----------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, '..')
sys.path.insert(0, project_root)
# -----------------------------------------------------

from moco_tics.modules import FrozenHubertBackbone
from util.utils import CrossAttentionBlock

class FeatureFusion(nn.Module):
    # å‡è®¾è¿™é‡Œçš„å®ç°ä¸ä¸Šä¸€ä¸ªå›å¤ä¸­çš„ FeatureFusion å®Œå…¨ç›¸åŒ
    def __init__(self, dim, layers_to_use: List[int], num_heads=8):
        super().__init__()
        self.layers_to_use = layers_to_use
        self.dim = dim # 768

        self.attention_blocks = nn.ModuleList([
            CrossAttentionBlock(dim, num_heads=num_heads)
            for _ in layers_to_use
        ])
        
        in_features = len(layers_to_use) * dim
        out_features = dim 
        self.fusion_projection = nn.Linear(in_features, out_features)
        
    def forward(self, features_dict: Dict[int, torch.Tensor]):
        batch_size = next(iter(features_dict.values())).shape[0]
        device = next(iter(features_dict.values())).device
        
        cls_token_template = torch.zeros(batch_size, 1, self.dim, device=device)

        all_cls_tokens = []
        
        for i, layer_idx in enumerate(self.layers_to_use):
            sequence_features = features_dict[layer_idx]
            x_with_cls = torch.cat([cls_token_template, sequence_features], dim=1)
            new_cls_token = self.attention_blocks[i](x_with_cls) 
            all_cls_tokens.append(new_cls_token)

        fused_cls_tokens = torch.cat(all_cls_tokens, dim=1) 
        fused_cls_tokens_flat = fused_cls_tokens.view(batch_size, -1) 
        fused_cls_token = self.fusion_projection(fused_cls_tokens_flat)
        
        sequence_features_for_boundary = features_dict[self.layers_to_use[-1]] 

        return sequence_features_for_boundary, fused_cls_token



class TICSBoundaryStudent(nn.Module):
    def __init__(self, input_dim=768, hidden_dim=256, dropout=0.1):
        super().__init__()
        
        # æ‹¼æ¥åçš„è¾“å…¥ç»´åº¦ = 768 (åºåˆ—) + 768 (å…¨å±€CLS) = 1536
        self.combined_input_dim = input_dim * 2 
        
        # 1. Bi-LSTM 1
        self.bi_lstm_1 = nn.LSTM(
            input_size=self.combined_input_dim, 
            hidden_size=hidden_dim, 
            num_layers=1,
            batch_first=True, 
            bidirectional=True
        )
        
        # 2. Bi-LSTM 2
        self.bi_lstm_2 = nn.LSTM(
            input_size=hidden_dim * 2, 
            hidden_size=hidden_dim, 
            num_layers=1,
            batch_first=True, 
            bidirectional=True
        )
        
        # 3. MLP Head (Tanh style)
        self.mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.Tanh(), 
            nn.Dropout(dropout),
            
            nn.Linear(128, 64),
            nn.Tanh(),
            nn.Dropout(dropout),
            
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
    def forward(self, sequence_features: torch.Tensor, fused_cls_token: torch.Tensor):
        B, T, C = sequence_features.shape
        
        # --- å…¨å±€è¯­å¢ƒæ³¨å…¥ ---
        global_context_expanded = fused_cls_token.unsqueeze(1).expand(-1, T, -1)
        combined_input = torch.cat([sequence_features, global_context_expanded], dim=-1)
        
        # --- Bi-LSTM å¤„ç† ---
        self.bi_lstm_1.flatten_parameters()
        self.bi_lstm_2.flatten_parameters()
        
        x, _ = self.bi_lstm_1(combined_input)
        x, _ = self.bi_lstm_2(x)
        
        # --- è¾¹ç•Œé¢„æµ‹ ---
        probs = self.mlp(x).squeeze(-1) # (B, T)
        
        return probs





import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple

# --- 1. ä¿®æ­£åçš„ Stop Gradient (sg) ---
class StopGradient(torch.autograd.Function):
    """
    Stop Gradient (sg) åŠŸèƒ½ï¼š
    å‰å‘ï¼šè¿”å›è¾“å…¥å€¼ (Identity)ã€‚
    åå‘ï¼šè¿”å› Noneï¼Œå³æ¢¯åº¦ä¸º 0ï¼Œé˜»æ­¢æ¢¯åº¦æµè¿‡æ­¤è·¯å¾„ã€‚
    """
    @staticmethod
    def forward(ctx, input):
        # å‰å‘ä¼ æ’­ï¼šä¿ç•™è¾“å…¥å€¼
        return input

    @staticmethod
    def backward(ctx, grad_output):
        # åå‘ä¼ æ’­ï¼šè¿”å› Noneï¼Œè¡¨ç¤ºè¾“å…¥å¯¹è¾“å‡ºçš„æ¢¯åº¦ä¸º 0ã€‚
        return None 
        
# é‡æ–°å®šä¹‰ sg ç¬¦å·ï¼Œå¯¹åº” SCPC è®ºæ–‡çš„ Stop Gradient
sg = StopGradient.apply

class SCPCBoundaryHardener(nn.Module):
    def __init__(self, soft_scale=10.0, hard_scale=1000.0):
        super().__init__()
        # SCPC è®ºæ–‡ä¸­çš„å›ºå®šå¸¸æ•° 10 å’Œ 1000
        self.soft_scale = soft_scale
        self.hard_scale = hard_scale
        self.tanh = nn.Tanh()

    def forward(self, P_score: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ ¹æ® SCPC è®ºæ–‡ Equation 5 å°†åŸå§‹åˆ†æ•° P_score (p) è½¬åŒ–ä¸ºå¯å¾®åˆ†çš„ç¡¬è¾¹ç•Œã€‚

        Args:
            P_score: (B, T) - TICSBoundaryStudent è¾“å‡ºçš„åŸå§‹åˆ†æ•° (Logits)ã€‚

        Returns:
            bsoft: (B, T) - ç”¨äºæŸå¤±è®¡ç®—çš„è½¯è¾¹ç•Œ (æ¢¯åº¦é€šè¿‡ bsoft æµåŠ¨)ã€‚
            b_hard_ste: (B, T) - ç”¨äºåˆ†æ®µåˆ‡åˆ†çš„ç¡¬è¾¹ç•Œ (å¸¦ STE æ¢¯åº¦)ã€‚
        """
        
        # 1. è½¯è¾¹ç•Œ (bsoft): ç”¨äºæ¢¯åº¦æµåŠ¨ï¼Œä½¿ç”¨è¾ƒå°çš„ç¼©æ”¾å› å­
        # bsoft = tanh(10 * p)
        bsoft = self.tanh(self.soft_scale * P_score)
        
        # 2. æç¡¬è¾¹ç•Œ (bhard): æ¥è¿‘ç¡¬äºŒå€¼åŒ–ï¼Œç”¨äº STE çš„å‰å‘è®¡ç®—
        # bhard = tanh(1000 * p)
        bhard = self.tanh(self.hard_scale * P_score)
        
        # 3. STE ç»„åˆ: b = bsoft + sg(bhard - bsoft)
        # å‰å‘ï¼š b_hard_ste çš„å€¼è¿‘ä¼¼äº bhard (ææ¥è¿‘ 0 æˆ– 1)
        # åå‘ï¼š æ¢¯åº¦åªæµç» bsoft è·¯å¾„ (é¿å… bhard è·¯å¾„ä¸Šçš„æ¢¯åº¦çˆ†ç‚¸)
        b_hard_ste = bsoft + sg(bhard - bsoft)
        
        return bsoft, b_hard_ste





#åˆ°åé¢æˆ‘ä»¬å¯ä»¥ä½¿ç”¨attetnionå»ä¼˜åŒ–åˆ†æ®µæ± åŒ–æ“ä½œ
def segment_pooling(sequence_features: torch.Tensor, hard_boundaries: torch.Tensor) -> List[torch.Tensor]:
    """
    ä½¿ç”¨ç¡¬è¾¹ç•Œ b_hard_ste å¯¹åºåˆ—ç‰¹å¾è¿›è¡Œåˆ†æ®µå¹³å‡æ± åŒ–ã€‚

    Args:
        sequence_features: (B, T, D) - åºåˆ—ç‰¹å¾ (æ¥è‡ª FeatureFusion)ã€‚
        hard_boundaries:   (B, T)    - äºŒå€¼åŒ–ç¡¬è¾¹ç•Œ b_hard_ste (0 æˆ– 1)ã€‚

    Returns:
        List[torch.Tensor]: åŒ…å« Batch ä¸­æ¯ä¸ª utterance çš„åˆ†æ®µç‰¹å¾åˆ—è¡¨ã€‚
                            æ¯ä¸ªå…ƒç´ æ˜¯ (Num_Segments, D) å½¢çŠ¶çš„ Tensorã€‚
    """
    batch_size, time_steps, dim = sequence_features.shape
    segmented_batch = []

    for b in range(batch_size):
        seq = sequence_features[b] # (T, D)
        bounds = hard_boundaries[b] # (T)
        
        # 1. æ‰¾åˆ°è¾¹ç•Œç´¢å¼•å¹¶å‡†å¤‡èµ·å§‹/ç»“æŸç‚¹
        # nonzero() è¿”å›ç´¢å¼• (ä¾‹å¦‚ï¼Œå¦‚æœ T=99ï¼Œè¾¹ç•Œåœ¨ç´¢å¼• 10, 25, 98)
        boundary_indices = torch.nonzero(bounds).squeeze(-1).tolist()
        
        # ç¡®ä¿èµ·å§‹ç‚¹æ˜¯ 0
        segment_points = [0] + [idx + 1 for idx in boundary_indices] 
        
        # ç¡®ä¿åŒ…å«åºåˆ—çš„ç»“æŸç‚¹
        if segment_points[-1] < time_steps:
             segment_points.append(time_steps)
        elif segment_points[-1] > time_steps:
             # å¤„ç†è¾¹ç•Œè½åœ¨åºåˆ—æœ«å°¾ T-1 çš„æƒ…å†µï¼Œç¡®ä¿ä¸è¶Šç•Œ
             segment_points[-1] = time_steps

        # 2. æ‰§è¡Œåˆ†æ®µå’Œæ± åŒ–
        segment_vectors = [] 
        
        # éå†æ‰€æœ‰ç‰‡æ®µ [start_i : start_{i+1}]
        for i in range(len(segment_points) - 1):
            start = segment_points[i]
            end = segment_points[i+1]
            
            if end > start: # ç¡®ä¿ç‰‡æ®µé•¿åº¦ > 0
                segment = seq[start:end] 
                
                # Mean Pooling (å¹³å‡æ± åŒ–) - å¯å¾®åˆ†
                pooled_vector = segment.mean(dim=0) 
                segment_vectors.append(pooled_vector)
        
        # 3. æç«¯æƒ…å†µå¤„ç†: å¦‚æœåºåˆ—ä¸­æ²¡æœ‰æ£€æµ‹åˆ°è¾¹ç•Œ
        if not segment_vectors and time_steps > 0:
             segment_vectors.append(seq.mean(dim=0))
            
        segmented_batch.append(torch.stack(segment_vectors, dim=0))

    return segmented_batch





from transformers import HubertModel
import torch
import torch.nn as nn

import torch.nn as nn
import torch.nn.functional as F

class SegmentEncoder(nn.Module):
    # åŒ¹é… HuBERT XLarge çš„æ ¸å¿ƒå‚æ•°
    HUGO_XLARGE_DIM = 1024
    HUGO_XLARGE_HEADS = 16  # HuBERT XLarge ä½¿ç”¨ 16 ä¸ªæ³¨æ„åŠ›å¤´
    
    def __init__(self, 
                 input_dim: int = 768,        # Segment Pooling å¾—åˆ°çš„ç‰¹å¾ç»´åº¦ (é€šå¸¸æ˜¯ HuBERT Base/Large çš„ 768)
                 segment_dim: int = HUGO_XLARGE_DIM, # æ•™å¸ˆæ¨¡å‹å¤„ç†çš„å†…éƒ¨ç»´åº¦ (1024)
                 num_layers: int = 12,        # ä½¿ç”¨ 12 å±‚ Transformer Encoder
                 num_heads: int = HUGO_XLARGE_HEADS,
                 max_segments: int = 1000,
                 dropout: float = 0.1):
        super().__init__()
        
        # 1. è¾“å…¥ç»´åº¦æŠ•å½±å±‚ (å…³é”®): 
        # ç”¨äºå°† Segment Pooling è¾“å‡ºçš„ç‰¹å¾ (e.g., 768D) æ˜ å°„åˆ° HuBERT XLarge çš„å†…éƒ¨ç»´åº¦ (1024D)ã€‚
        # å¦‚æœæ‚¨çš„ HuBERT Backbone å·²ç»æ˜¯ 1024Dï¼Œè¿™ä¸ªå±‚å°±æ˜¯ nn.Identity() æˆ–ç›´æ¥è·³è¿‡ã€‚
        self.input_projection = nn.Linear(input_dim, segment_dim)
        
        # 2. ä½ç½®ç¼–ç  (ç”¨äºæ•è·ç‰‡æ®µçš„é¡ºåºä¿¡æ¯)
        self.pos_encoder = nn.Embedding(max_segments, segment_dim) 
        self.dropout = nn.Dropout(dropout)
        
        # 3. Transformer Encoder Layer
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=segment_dim, 
            nhead=num_heads, 
            dim_feedforward=segment_dim * 4, # é»˜è®¤ MLP æ‰©å±•ç³»æ•°
            dropout=dropout,
            batch_first=False # (T, B, D) æ ¼å¼
        )
        
        # 4. Transformer Encoder (å †å  num_layers ä¸ªå±‚)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
    def forward(self, segments: torch.Tensor, padding_mask: torch.BoolTensor) -> torch.Tensor:
        """
        Args:
            segments: (T, B, D_in) - å¡«å……åçš„ç‰‡æ®µåºåˆ—ï¼ŒD_in æ˜¯è¾“å…¥ç»´åº¦ (e.g., 768)
            padding_mask: (B, T) - Transformer çš„ Key Padding Mask (True=Masked)

        Returns:
            output: (T, B, D_seg) - ç¼–ç åçš„ç‰‡æ®µåºåˆ—è¡¨ç¤º (D_seg=1024)
        """
        time_steps, batch_size, dim_in = segments.shape
        device = segments.device
        
        # 1. æŠ•å½±åˆ°æ•™å¸ˆæ¨¡å‹ç»´åº¦ (768 -> 1024)
        x = self.input_projection(segments)
        
        # 2. æ·»åŠ ä½ç½®ç¼–ç 
        position_indices = torch.arange(time_steps, device=device) 
        pos_embedding = self.pos_encoder(position_indices).unsqueeze(1).expand(-1, batch_size, -1)
        
        x = x + pos_embedding
        x = self.dropout(x)
        
        # 3. è¿è¡Œ Transformer ç¼–ç å™¨
        # src_key_padding_mask: å‘Šè¯‰ Transformer å¿½ç•¥å“ªäº›å…ƒç´ ï¼ˆå¡«å……éƒ¨åˆ†ï¼‰
        output = self.transformer_encoder(x, src_key_padding_mask=padding_mask)
        
        return output

# =======================================================
# é›†æˆæµ‹è¯•å‡½æ•°
# =======================================================
def test_integration():
    print("--- Starting HuBERT Backbone & Fusion Integration Test ---")
    
    # 1. é…ç½®å‚æ•°
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    BATCH_SIZE = 2
    SAMPLE_RATE = 16000
    DURATION_SEC = 2
    TIME_SAMPLES = SAMPLE_RATE * DURATION_SEC
    DIMENSION = 768
    LAYERS_TO_EXTRACT = [2, 5, 9] # æ‚¨çš„é€‰æ‹©

    # 2. æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    fake_wav = torch.randn(BATCH_SIZE, TIME_SAMPLES, device=device) 
    print(f"Input WAV shape: {fake_wav.shape}")
    
    # 3. å®ä¾‹åŒ– HuBERT Backbone
    LOCAL_MODEL_PATH = "/mnt/facebook/hubert-base-ls960" # æ‚¨çš„æœ¬åœ°è·¯å¾„
    backbone = FrozenHubertBackbone(model_path=LOCAL_MODEL_PATH).to(device)
    
    # 4. è¿è¡Œ HuBERT å‰å‘ä¼ æ’­
    print(f"Extracting features from layers {LAYERS_TO_EXTRACT}...")
    features_dict = backbone(fake_wav, layers_to_extract=LAYERS_TO_EXTRACT)
    
    # éªŒè¯ HuBERT è¾“å‡º
    first_key = LAYERS_TO_EXTRACT[0]
    first_feature_shape = features_dict[first_key].shape
    TIME_FRAMES = first_feature_shape[1] # åŠ¨æ€è·å–å¸§æ•° (ä¾‹å¦‚ 99)
    print(f"HuBERT Layer {first_key} output shape: {first_feature_shape}")
    
    # 5. å®ä¾‹åŒ–ç‰¹å¾èåˆæ¨¡å—
    fusion_model = FeatureFusion(dim=DIMENSION, layers_to_use=LAYERS_TO_EXTRACT).to(device)
    
    # 6. è¿è¡Œèåˆæ¨¡å—
    print("Running Cross-Attention Fusion...")
    sequence_features_for_boundary, fused_cls = fusion_model(features_dict)

    # 7. å®ä¾‹åŒ–å­¦ç”Ÿæ¨¡å‹
    student_model = TICSBoundaryStudent(input_dim=DIMENSION).to(device)
    hardener_model = SCPCBoundaryHardener().to(device)

    # 8. è¿è¡Œå­¦ç”Ÿæ¨¡å‹
    print("Running TICS Boundary Student...")
    P_score = student_model(sequence_features_for_boundary, fused_cls)
    

    # 9. è¿è¡Œç¡¬åŒ–æ¨¡å—
    print("Running SCPC Boundary Hardener...")
    b_soft, b_hard_ste = hardener_model(P_score)


    # ====================================================
    # 10. SCPC Hardener ä¸“é¡¹åŠŸèƒ½æµ‹è¯• (æ ¸å¿ƒæ–°å¢éƒ¨åˆ†)
    # ====================================================
    print("\n--- Hardener Functional & STE Test ---")
    
    # Test A: è¾¹ç•Œå€¼æ£€æŸ¥ (éªŒè¯è½¯ç¡¬åŒ–æ•ˆæœ)
    # æ¨¡æ‹Ÿè¾“å…¥ P_scoreï¼Œçœ‹ b_soft å’Œ b_hard_ste çš„å·®å¼‚
    fake_p_scores = torch.tensor([[0.01, 0.5, 0.999]], device=device)
    test_b_soft, test_b_hard_ste = hardener_model(fake_p_scores)
    
    # b_soft (tanh(10*P)) åº”è¯¥æ˜¾ç¤ºæ›´æŸ”å’Œçš„é˜ˆå€¼æ•ˆåº”
    # b_hard_ste (tanh(1000*P)) åº”è¯¥æ˜¾ç¤ºæç¡¬çš„äºŒå€¼åŒ–æ•ˆåº”
    print(f"Test P_scores: {fake_p_scores.squeeze().tolist()}")
    print(f"Test b_soft:   {test_b_soft.squeeze().tolist()}")
    print(f"Test b_hard:   {test_b_hard_ste.squeeze().tolist()}")
    
    # æ£€æŸ¥ç¡¬è¾¹ç•Œæ˜¯å¦æ¥è¿‘ 1 (é™¤äº†æå°å€¼ 0.01 ä»¥å¤–)
    assert test_b_hard_ste[0][1].item() > 0.99999, "ç¡¬è¾¹ç•Œ b_hard_ste æœªèƒ½å¯¹ 0.5 è¾“å…¥è¿›è¡Œç¡¬åŒ–ã€‚"
    print("Check 1: ç¡¬è¾¹ç•Œ b_hard_ste æˆåŠŸç¡¬åŒ–è¾“å…¥ P_score (PASS)")

    # Test B: æ¢¯åº¦æµæ£€æŸ¥ (éªŒè¯ STE æœºåˆ¶)
    
    # é‡æ–°åˆ›å»ºä¸€ä¸ª P_score å¼ é‡ï¼Œå¹¶è¦æ±‚æ¢¯åº¦
    P_score_test = torch.tensor([[0.5]], device=device, requires_grad=True)
    
    # è¿è¡Œç¡¬åŒ–æ¨¡å—
    b_soft_test, b_hard_ste_test = hardener_model(P_score_test)
    
    # å‡æŸå¤± L = sum(b_hard_ste * 2)ã€‚æ¢¯åº¦ dL/d(b_hard_ste) = 2
    fake_loss = (b_hard_ste_test * 2).sum() 
    
    # åå‘ä¼ æ’­
    fake_loss.backward()
    
    # é¢„æœŸæ¢¯åº¦ dL/dP = d(b_soft)/dP * dL/d(b_hard_ste) 
    # = [10 * sech^2(10*p)] * 2
    scale = 10.0
    p_val = P_score_test.item()
    expected_grad = 2.0 * scale * (1.0 - torch.tanh(scale * P_score_test)**2) 
    
    actual_grad = P_score_test.grad
    
    # æ£€æŸ¥ P_score_test çš„æ¢¯åº¦ (å…è®¸æµ®ç‚¹è¯¯å·®)
    is_grad_correct = torch.allclose(actual_grad, expected_grad, atol=1e-5)
    assert is_grad_correct, f"Check 2: STEæ¢¯åº¦å¤±è´¥ã€‚å®é™…: {actual_grad.item()}, é¢„æœŸ: {expected_grad.item()}"
    print("Check 2: STE æ¢¯åº¦æµéªŒè¯ (PASS)")
    
    print("--- Hardener Functional & STE Test Passed ---")


    # 11. æœ€ç»ˆéªŒè¯ (å½¢çŠ¶éªŒè¯)
    print("\n--- Final Verification Results ---")
    
    # c. å­¦ç”Ÿæ¨¡å‹è¾“å‡ºå½¢çŠ¶
    expected_prob_shape = (BATCH_SIZE, TIME_FRAMES)
    assert P_score.shape == expected_prob_shape
    print(f"Student P_score Shape: {P_score.shape} (PASS)")
    
    # d. è¾¹ç•Œè¾“å‡ºå½¢çŠ¶ (æ–°å¢)
    assert b_soft.shape == expected_prob_shape
    assert b_hard_ste.shape == expected_prob_shape
    print(f"Soft Boundary b_soft Shape: {b_soft.shape} (PASS)")
    print(f"Hard Boundary b_hard_ste Shape: {b_hard_ste.shape} (PASS) âœ…")

    # e. è®¾å¤‡éªŒè¯
    assert b_hard_ste.device == device
    print(f"Output Device: {device} (PASS)")
    
    print("\nğŸ‰ End-to-End Dataflow Test (HuBERT -> Fusion -> Student -> Hardener) passed successfully!")


    from torch.nn.utils.rnn import pad_sequence

    # ====================================================
    # 11. Segment Pooling ä¸“é¡¹æµ‹è¯• (æ–°å¢)
    # ====================================================
    print("\n--- Segment Pooling Functional & Differentiability Test ---")

    # å‡†å¤‡æ¨¡æ‹Ÿæ•°æ® (Batch Size=1)
    TEST_SEQ_LEN = 10
    TEST_DIM = 5
    # ç¡®ä¿ç‰¹å¾éœ€è¦æ¢¯åº¦ï¼Œä»¥ä¾¿åç»­æ£€æŸ¥æ¢¯åº¦æ˜¯å¦èƒ½æµå›
    fake_seq_features = torch.arange(
        TEST_SEQ_LEN * TEST_DIM, 
        dtype=torch.float, 
        device=device
    ).view(1, TEST_SEQ_LEN, TEST_DIM)
    fake_seq_features.requires_grad_(True) # <-- å¿…é¡»è¦æ±‚æ¢¯åº¦

    # æ¨¡æ‹Ÿç¡¬è¾¹ç•Œ: åœ¨ç´¢å¼• 3 å’Œ 7 å¤„åˆ‡åˆ†
    # 0 1 2 3| 4 5 6 7| 8 9
    # è¾¹ç•Œç‚¹ (1) åœ¨ç´¢å¼• 3 å’Œ 7
    # è¾¹ç•Œç‚¹+1 (æ–°ç‰‡æ®µå¼€å§‹) åœ¨ç´¢å¼• 4 å’Œ 8
    fake_boundaries = torch.tensor([
        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0] 
    ], dtype=torch.float, device=device)

    # 1. æ‰§è¡Œåˆ†æ®µæ± åŒ–
    segmented_list = segment_pooling(
        sequence_features=fake_seq_features, 
        hard_boundaries=fake_boundaries
    )

    # --- Check A: åŠŸèƒ½æ­£ç¡®æ€§ (åˆ†æ®µæ•°é‡å’Œæ•°å€¼) ---
    assert len(segmented_list) == 1, "åˆ†æ®µæ± åŒ– Batch Size é”™è¯¯ã€‚"
    segments = segmented_list[0] # (Num_Segments, D)

    # é¢„æœŸåˆ†æ®µæ•°é‡: 3 ä¸ªç‰‡æ®µ (0-3, 4-7, 8-9)
    expected_num_segments = 3
    assert segments.shape[0] == expected_num_segments, \
        f"Check A1: åˆ†æ®µæ•°é‡é”™è¯¯ã€‚é¢„æœŸ {expected_num_segments}, å®é™… {segments.shape[0]}"
    print(f"Check A1: åˆ†æ®µæ•°é‡ {expected_num_segments} (PASS)")

    # éªŒè¯ç¬¬ä¸€ä¸ªç‰‡æ®µçš„å‡å€¼ (0:4 ç´¢å¼•)
    # å¯¹åº”å¼ é‡å…ƒç´  0, 1, 2, 3ï¼Œæ¯ä¸ªéƒ½æ˜¯ 5 ç»´å‘é‡ã€‚
    # éªŒè¯ç¬¬ä¸€ä¸ªç»´åº¦ (D=0) çš„å‡å€¼: (0+5+10+15) / 4 = 7.5
    expected_first_dim_mean = (fake_seq_features[0, 0, 0] + 
                            fake_seq_features[0, 1, 0] + 
                            fake_seq_features[0, 2, 0] + 
                            fake_seq_features[0, 3, 0]) / 4
                            
    assert torch.allclose(segments[0, 0], expected_first_dim_mean, atol=1e-5), \
        f"Check A2: ç¬¬ä¸€ä¸ªç‰‡æ®µçš„å‡å€¼è®¡ç®—é”™è¯¯ã€‚é¢„æœŸ {expected_first_dim_mean.item()}, å®é™… {segments[0, 0].item()}"
    print("Check A2: ç‰‡æ®µå‡å€¼è®¡ç®— (PASS)")


    # --- Check B: å¯å¾®åˆ†æ€§ (æ¢¯åº¦æµåŠ¨) ---
    # å‡è®¾ä¸€ä¸ªç®€å•çš„æŸå¤±: æ‰€æœ‰ç‰‡æ®µå‘é‡çš„æ€»å’Œ
    dummy_loss = segments.sum()
    dummy_loss.backward()

    # éªŒè¯è¾“å…¥ç‰¹å¾çš„æ¢¯åº¦æ˜¯å¦ä¸ºéé›¶
    # ç”±äºåˆ†æ®µæ± åŒ–æ˜¯å¹³å‡æ“ä½œï¼Œæ‰€æœ‰è¢«ä½¿ç”¨çš„è¾“å…¥å¸§éƒ½åº”æœ‰éé›¶æ¢¯åº¦ã€‚
    assert fake_seq_features.grad is not None, "Check B1: æ¢¯åº¦å¯¹è±¡ä¸å­˜åœ¨ã€‚"
    assert fake_seq_features.grad.abs().sum().item() > 0, "Check B2: æ¢¯åº¦ä¸ºé›¶ï¼Œæ± åŒ–æ“ä½œä¸å¯å¾®åˆ†ã€‚"

    # éªŒè¯æ¢¯åº¦åˆ†å¸ƒ (ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªç‰‡æ®µ (0:4) çš„æ¢¯åº¦åº”è¯¥ç›¸ç­‰)
    expected_grad_value = 1.0 / 4.0 # 1/ç‰‡æ®µé•¿åº¦ (4)
    actual_grad_value = fake_seq_features.grad[0, 0, 0].item()

    # å…è®¸æµ®ç‚¹è¯¯å·®
    is_grad_correct = torch.allclose(
        torch.tensor(actual_grad_value), 
        torch.tensor(expected_grad_value), 
        atol=1e-5
    )
    assert is_grad_correct, \
        f"Check B3: æ¢¯åº¦å€¼é”™è¯¯ã€‚é¢„æœŸ {expected_grad_value}, å®é™… {actual_grad_value}"
    print("Check B3: æ¢¯åº¦å›ä¼ ä¸å¹³å‡æ“ä½œç›¸ç¬¦ (PASS) âœ…")


    # --- Check C: å¡«å……ä¸ Mask ç”Ÿæˆ ---
    # è¿™ä¸€æ­¥æ˜¯ä¸ºæ•™å¸ˆæ¨¡å‹ E_seg å‡†å¤‡è¾“å…¥

    # 1. å¡«å……åˆ° Batch å¼ é‡
    # å¿…é¡»ä½¿ç”¨é›†æˆæµ‹è¯•çš„å®é™…è¾“å‡º
    final_segmented_list = segmented_list # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œä½†å®é™…åº”è¯¥ä½¿ç”¨ segmented_list

    # Pad Sequence é»˜è®¤è¿”å› (Max_Segments, B, D)
    padded_segments_TBD = pad_sequence(final_segmented_list, batch_first=False) 
    # shape: (3, 1, 5)

    # 2. åˆ›å»º Mask
    batch_sizes = [s.shape[0] for s in final_segmented_list]
    max_len = padded_segments_TBD.shape[0]

    # åˆ›å»ºä¸€ä¸ªå……æ»¡ True çš„å¸ƒå°”å¼ é‡
    padding_mask = torch.ones(
        (len(batch_sizes), max_len), 
        dtype=torch.bool, 
        device=device
    )

    # æ ‡è®°çœŸå®æ•°æ®ä¸º False (å³ä¸è¢« Mask)
    for i, length in enumerate(batch_sizes):
        padding_mask[i, :length] = False 
        
    # éªŒè¯å½¢çŠ¶
    assert padded_segments_TBD.shape == (expected_num_segments, 1, TEST_DIM)
    assert padding_mask.shape == (1, expected_num_segments)

    # éªŒè¯ Mask å€¼ (æ‰€æœ‰éƒ½åº”è¯¥æ˜¯ Falseï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ªæ ·æœ¬ä¸”æ²¡æœ‰å¡«å……)
    assert not padding_mask.all().item(), "Check C: å¡«å…… Mask å€¼é”™è¯¯ï¼Œä¸åº”å…¨ä¸º Trueã€‚"

    print(f"Check C1: å¡«å……å¼ é‡å½¢çŠ¶ {padded_segments_TBD.shape} (PASS)")
    print(f"Check C2: å¡«å…… Mask å½¢çŠ¶ {padding_mask.shape} (PASS)")

    print("--- Segment Pooling Test Passed ---")


    # ----------------------------------------------------
    # 12. SegmentEncoder Functional & Differentiability Test
    # ----------------------------------------------------
    print("\n--- SegmentEncoder Test (Teacher Model) ---")

    TEST_D_IN = 768
    TEST_D_OUT = 1024
    TEST_BATCH_SIZE = 2
    TEST_NUM_LAYERS = 4 

    # --- A. å‡†å¤‡æ¨¡æ‹Ÿ Segment Pooling è¾“å‡º (Batch Size = 2) ---

    # æ ·æœ¬ 1: 3 ä¸ªç‰‡æ®µ (å¶èŠ‚ç‚¹)
    segment_1 = torch.randn(3, TEST_D_IN, device=device, requires_grad=True)
    # æ ·æœ¬ 2: 5 ä¸ªç‰‡æ®µ (å¶èŠ‚ç‚¹)
    segment_2 = torch.randn(5, TEST_D_IN, device=device, requires_grad=True)

    # 1. å¡«å……åˆ° Batch å¼ é‡
    # Max_Segments = 5ã€‚è¾“å‡ºå½¢çŠ¶: (Max_Segments, B, D) -> (5, 2, 768)
    # æ³¨æ„ï¼šéœ€è¦ç¡®ä¿å¯¼å…¥äº† pad_sequence
    from torch.nn.utils.rnn import pad_sequence 

    padded_segments_TBD = pad_sequence([segment_1, segment_2], batch_first=False) 

    # FIX: æ˜¾å¼å‘Šè¯‰ PyTorch ä¿ç•™è¿™ä¸ªéå¶å¼ é‡çš„æ¢¯åº¦
    padded_segments_TBD.retain_grad()

    # 2. åˆ›å»º Mask
    batch_lengths = [s.shape[0] for s in [segment_1, segment_2]] 
    max_len = padded_segments_TBD.shape[0] 

    # åˆå§‹åŒ– Mask (B, T) -> (2, 5)
    padding_mask = torch.ones(
        (TEST_BATCH_SIZE, max_len), 
        dtype=torch.bool, 
        device=device
    )

    # æ ‡è®°çœŸå®æ•°æ®ä¸º False (å³ä¸è¢« Mask)
    for i, length in enumerate(batch_lengths):
        padding_mask[i, :length] = False 
        
    # --- B. å®ä¾‹åŒ–å’Œå‰å‘ä¼ æ’­ ---

    # ä½¿ç”¨æ¨¡æ‹Ÿçš„ SegmentEncoder 
    teacher_encoder = SegmentEncoder(
        input_dim=TEST_D_IN, 
        segment_dim=TEST_D_OUT,
        num_layers=TEST_NUM_LAYERS 
    ).to(device)

    for param in teacher_encoder.parameters():
        param.requires_grad = True

    # æ‰§è¡Œå‰å‘ä¼ æ’­
    try:
        segment_embeddings = teacher_encoder(padded_segments_TBD, padding_mask) # (T, B, D_out)
        
    except Exception as e:
        print(f"Check B: SegmentEncoder å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        raise e # å¦‚æœå¤±è´¥ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸

    # --- C. æ£€æŸ¥å½¢çŠ¶å’ŒåŠŸèƒ½ ---

    expected_shape = (max_len, TEST_BATCH_SIZE, TEST_D_OUT) 
    assert segment_embeddings.shape == expected_shape, \
        f"Check C1: è¾“å‡ºå½¢çŠ¶é”™è¯¯ã€‚é¢„æœŸ {expected_shape}, å®é™… {segment_embeddings.shape}"
    print(f"Check C1: è¾“å‡ºå½¢çŠ¶ {segment_embeddings.shape} (PASS)")

    # æ£€æŸ¥å¡«å……ä½ç½®çš„æ¢¯åº¦æ˜¯å¦ä¸ºé›¶ (æœ€ä¸¥æ ¼çš„æ£€æŸ¥)
    dummy_loss = segment_embeddings.sum()
    dummy_loss.backward()

    # --- D. æ£€æŸ¥æ¢¯åº¦æµåŠ¨ ---

    # D1: æ£€æŸ¥ Encoder æƒé‡æ˜¯å¦æœ‰æ¢¯åº¦
    encoder_grads = sum([p.grad.abs().sum().item() for p in teacher_encoder.parameters() if p.grad is not None])
    assert encoder_grads > 0, "Check D1: SegmentEncoder æƒé‡æ¢¯åº¦ä¸ºé›¶ï¼Œä¸å¯è®­ç»ƒã€‚"
    print("Check D1: æ•™å¸ˆæ¨¡å‹æƒé‡æ¢¯åº¦ (PASS) âœ…")

    # D2: æ£€æŸ¥è¾“å…¥å¶å¼ é‡ (segment_1, segment_2) çš„æ¢¯åº¦æ˜¯å¦éé›¶ (åŸå§‹è¾“å…¥)
    input_grad_sum = segment_1.grad.abs().sum().item() + segment_2.grad.abs().sum().item()
    assert input_grad_sum > 0, "Check D2: æ¢¯åº¦æœªæµå› Segment Pooling è¾“å‡ºã€‚"
    print("Check D2: æ¢¯åº¦å›ä¼ åˆ° Segment Pooling è¾“å‡º (PASS) âœ…")

    # D3: æ£€æŸ¥å¡«å……ä½ç½®çš„æ¢¯åº¦æ˜¯å¦è¢«å±è”½ (éªŒè¯ Masking æœºåˆ¶)
    # æ ·æœ¬ 1 å¡«å……ä½ç½®çš„ç´¢å¼• (3, 4)
    # ç°åœ¨ padded_segments_TBD.grad å·²ç»è¢« retain_grad() å¡«å……äº†
    grad_at_padding_sample1 = padded_segments_TBD.grad[3:, 0, :].abs().sum().item() 
    assert torch.isclose(torch.tensor(grad_at_padding_sample1), torch.tensor(0.0), atol=1e-5), \
        f"Check D3: å¡«å……ä½ç½®æ¢¯åº¦éé›¶ã€‚å®é™…æ€»å’Œ: {grad_at_padding_sample1}"
    print("Check D3: å¡«å……ä½ç½®æ¢¯åº¦è¢«æœ‰æ•ˆå±è”½ (PASS) âœ…")

    print("--- SegmentEncoder Test Passed ---")



if __name__ == "__main__":
    # è¯·ç¡®ä¿ Mlp, DropPath, CrossAttention, CrossAttentionBlock çš„å®šä¹‰åœ¨è¿è¡Œç¯å¢ƒä¸­å¯ç”¨
    # å¦åˆ™éœ€è¦å…ˆå°†è¿™äº›ä»£ç ç²˜è´´åˆ° test_fusion_integrated.py çš„é¡¶éƒ¨
    test_integration()