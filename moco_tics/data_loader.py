import torch
import torchaudio
import numpy as np
import random
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
from transformers import XLMRobertaTokenizer
from typing import List, Tuple, Dict
import pandas as pd
import os
import json
from .TicsAugmentation import TicsAugmentation
import pandas as pd
import orjson
from tqdm import tqdm


class BoundaryLabelGenerator:
    def __init__(self, fps=50):
        self.fps = fps

    def generate(self, data: dict, target_frames: int) -> torch.Tensor:
        """
        ä¸å†è¯»ç£ç›˜ï¼Œç›´æ¥å¤„ç†ä¼ å…¥çš„å†…å­˜å­—å…¸å¯¹è±¡
        """
        try:
            # æ­¤æ—¶ data å·²ç»æ˜¯ TICSDataset ä¼ è¿›æ¥çš„å­—å…¸äº†
            if data is None:
                return torch.zeros(target_frames, dtype=torch.float32)

            y_true = torch.zeros(target_frames, dtype=torch.float32)
            words = data.get('words', data.get('word_segments', []))
            
            for word in words:
                # è½¬æ¢åˆ°å¸§ç´¢å¼•: frame = time * 50
                frame_idx = int(round(word['end'] * self.fps))
                
                # ä¸¥æ ¼è¾¹ç•Œæ£€æŸ¥
                if frame_idx < target_frames:
                    y_true[frame_idx] = 1.0
                elif frame_idx == target_frames: 
                    y_true[target_frames - 1] = 1.0
                    
            return y_true
        except Exception as e:
            # æ‰“å°é”™è¯¯æ–¹ä¾¿æ’æŸ¥ï¼Œä½†è¿”å›å…¨ 0 ä¿è¯è®­ç»ƒä¸å´©æºƒ
            print(f"Label generation error: {e}")
            return torch.zeros(target_frames, dtype=torch.float32)

class TICSDataset(Dataset):
    def __init__(self, csv_path: str, sample_rate: int = 16000, xlmr_path="/mnt/facebook/xlm-roberta-large", augmentor=None, stage=1):
        self.stage = stage
        self.sample_rate = sample_rate
        
        # 1. æ›´åŠ å¥å£®çš„ CSV åŠ è½½
        print(f"ğŸ” æ­£åœ¨åŠ è½½ CSV æ–‡ä»¶: {csv_path}")
        # å¦‚æœä½ çš„ CSV ç¡®å®æ²¡æœ‰è¡¨å¤´ï¼Œç”¨ header=Noneï¼›å¦‚æœæœ‰ï¼Œç”¨ header=0
        df = pd.read_csv(csv_path, header=None) 
        # 2. æ ¸å¿ƒï¼šè¿‡æ»¤æ‰éè·¯å¾„çš„æ— æ•ˆè¡Œï¼ˆæ¯”å¦‚è¡¨å¤´æ–‡å­—ï¼‰
        # åªæœ‰å½“ç¬¬ä¸€åˆ—åŒ…å« '/' (è·¯å¾„ç‰¹å¾) ä¸”ä¸ä¸ºç©ºæ—¶æ‰ä¿ç•™
        valid_mask = df.iloc[:, 0].str.contains('/', na=False)
        df = df[valid_mask]
        
        self.audio_files = df.iloc[:, 0].tolist()
        self.json_files = df.iloc[:, 1].tolist() 
        
        self.cached_json = []
        print(f"ğŸš€ å†…å­˜å……è¶³ï¼Œæ­£åœ¨é¢„åŠ è½½ {len(self.json_files)} æ¡ JSON ç‰¹å¾...")
        
        # é¢„åŠ è½½å¾ªç¯
        for json_p in tqdm(self.json_files, desc="Caching JSONs", unit="file"):
            try:
                with open(json_p, 'rb') as f:
                    # ä½¿ç”¨ orjson å¿«é€Ÿè§£æäºŒè¿›åˆ¶æµ
                    # å­˜å…¥åˆ—è¡¨åï¼Œ__getitem__ è®¿é—®é€Ÿåº¦æ˜¯ O(1) ä¸”é›¶ç£ç›˜ IO
                    self.cached_json.append(orjson.loads(f.read()))
            except Exception as e:
                print(f"Error loading {json_p}: {e}")
                # ä¸ºäº†ç´¢å¼•å¯¹åº”ï¼ŒåŠ è½½å¤±è´¥ä¹Ÿå ä¸ªä½ï¼ˆæˆ–è€…åœ¨ä¹‹å‰è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼‰
                self.cached_json.append(None)

        print(f"âœ… é¢„åŠ è½½å®Œæˆã€‚å½“å‰æ ·æœ¬æ€»æ•°: {len(self.audio_files)}")



        # ç»„ä»¶åˆå§‹åŒ–
        self.tokenizer = XLMRobertaTokenizer.from_pretrained(xlmr_path)
        self.augmentor = augmentor if augmentor else TicsAugmentation(mode='none')
        self.label_gen = BoundaryLabelGenerator(fps=50)

    def __len__(self):
        return len(self.audio_files)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        try:
            #print(f"DEBUG: [Rank {torch.distributed.get_rank()}] Loading Index: {idx}")
            audio_path = self.audio_files[idx]
            json_data = self.cached_json[idx]
            # --- å…³é”®è°ƒè¯•ç‚¹ï¼šå¦‚æœè¿˜æ˜¯æŠ¥é”™ï¼Œè¿™é‡Œä¼šæ‰“å°å‡ºå…·ä½“çš„è·¯å¾„å†…å®¹ ---
            if json_data is None:
            # å®é™…ç”Ÿäº§ä¸­å»ºè®®è¿”å›ä¸€ä¸ª dummy æ ·æœ¬æˆ–åœ¨ init ä¸­å‰”é™¤é”™è¯¯
                return self.__getitem__((idx + 1) % len(self))


            # 2. åŠ è½½éŸ³é¢‘
            if not os.path.exists(audio_path):
                return self.__getitem__((idx + 1) % len(self))
                
            waveform, sr = torchaudio.load(audio_path)
             
            # 3. è®¡ç®— HuBERT å¸§æ•°å¹¶è¿‡æ»¤è¶…çŸ­éŸ³é¢‘
            target_T = waveform.shape[1] // 320
            if target_T <= 1: 
                return self.__getitem__((idx + 1) % len(self))

            # 4. ç”Ÿæˆæ ‡ç­¾ (ä¼ å…¥ json_path æˆ– metaï¼Œå–å†³äºä½  Generator çš„å®ç°)
            y_true = self.label_gen.generate(json_data, target_T)

            # 5. ç”Ÿæˆå¢å¼ºè§†å›¾
            view1 = self.augmentor(waveform, is_view2=False)
            view2 = self.augmentor(waveform, is_view2=True)

            if self.stage == 2:
                text = json_data.get('text', "")
                encoded_text = self.tokenizer(
                    text,
                    padding='max_length',
                    truncation=True,
                    max_length=128,
                    return_tensors='pt'
                )
                return {
                    "view1": view1.squeeze(0),
                    "y_true": y_true,
                    "text_ids": encoded_text['input_ids'].squeeze(0),
                    "text_mask": encoded_text['attention_mask'].squeeze(0)
                }

            return {
                "view1": view1.squeeze(0),
                "view2": view2.squeeze(0),
                "y_true": y_true
            }

        except Exception as e:
            # ä¸‡èƒ½æ•è·ï¼Œç¡®ä¿ 400 ä¸‡è®­ç»ƒä¸ä¼šå› ä¸ºæŸä¸€ä¸ª json æ ¼å¼é”™è¯¯è€Œä¸­æ–­
            # print(f"âŒ ç´¢å¼• {idx} åŠ è½½å´©æºƒ: {str(e)}")
            return self.__getitem__((idx + 1) % len(self))
        

def tics_collate_fn(batch):
    """
    å…¼å®¹ Stage I å’Œ Stage II çš„åŠ¨æ€ Padding å‡½æ•°
    """
    # 1. åŸºç¡€é¡¹æå– (æ‰€æœ‰é˜¶æ®µå…±æœ‰)
    view1_list = [item['view1'] for item in batch]
    y_true_list = [item['y_true'] for item in batch]
    
    # å¯¹éŸ³é¢‘å’Œè¾¹ç•Œæ ‡ç­¾è¿›è¡Œ Padding
    padded_view1 = pad_sequence(view1_list, batch_first=True, padding_value=0.0)
    padded_y_true = pad_sequence(y_true_list, batch_first=True, padding_value=0.0)
    
    # ç”ŸæˆéŸ³é¢‘æ©ç  y_mask (ç”¨äº Boundary Loss æ’é™¤ padding éƒ¨åˆ†)
    # y_true å½¢çŠ¶ä¸º (B, T)ï¼Œy_mask åœ¨æœ‰æ•ˆé•¿åº¦ä¸º 1ï¼Œpadding ä¸º 0
    lengths = [len(y) for y in y_true_list]
    max_len = max(lengths)
    y_mask = torch.zeros((len(batch), max_len), dtype=torch.float32)
    for i, l in enumerate(lengths):
        y_mask[i, :l] = 1.0

    # æ„é€ åŸºç¡€è¿”å›å­—å…¸
    output = {
        "view1": padded_view1,
        "y_true": padded_y_true,
        "y_mask": y_mask
    }

    # 2. Stage I ç‰¹æœ‰é¡¹ï¼šå¤„ç† view2 (å¯¹æ¯”è§†å›¾)
    if 'view2' in batch[0]:
        view2_list = [item['view2'] for item in batch]
        output["view2"] = pad_sequence(view2_list, batch_first=True, padding_value=0.0)

    # 3. Stage II ç‰¹æœ‰é¡¹ï¼šå¤„ç†æ–‡æœ¬ Token
    if 'text_ids' in batch[0]:
        text_ids_list = [item['text_ids'] for item in batch]
        text_mask_list = [item['text_mask'] for item in batch]
        
        # æ–‡æœ¬é€šå¸¸åœ¨ Dataset é‡Œå·²ç»å›ºå®šäº† max_lengthï¼Œä½†ä¿é™©èµ·è§è¿™é‡Œå†åšä¸€æ¬¡ pad
        output["text_ids"] = pad_sequence(text_ids_list, batch_first=True, padding_value=1) # XLM-R pad ID é€šå¸¸æ˜¯ 1ï¼Œè¯·æ ¹æ® tokenizer ç¡®è®¤
        output["text_mask"] = pad_sequence(text_mask_list, batch_first=True, padding_value=0.0)

    return output



def get_tics_dataloader(csv_path: str, batch_size: int, num_workers: int):
    dataset = TICSDataset(csv_path)
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=tics_collate_fn,
        pin_memory=True
    )