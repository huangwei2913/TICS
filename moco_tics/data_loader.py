import torch
import torchaudio
import numpy as np
import random
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
from transformers import XLMRobertaTokenizer
from typing import List, Tuple, Dict
import pandas as pd
import os
import json
from .TicsAugmentation import TicsAugmentation



class BoundaryLabelGenerator:
    def __init__(self, fps=50):
        self.fps = fps

    def generate(self, json_path: str, target_frames: int) -> torch.Tensor:
        """
        åŸºäºç»™å®šçš„å¸§æ•°ç”Ÿæˆ 0/1 åºåˆ—
        """
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            y_true = torch.zeros(target_frames, dtype=torch.float32)
            words = data.get('words', data.get('word_segments', []))
            
            for word in words:
                # æå–è¯è¾¹ç•Œç»“æŸæ—¶é—´
                end_time = word['end']
                # è½¬æ¢åˆ°å¸§ç´¢å¼•: frame = time * 50
                frame_idx = int(round(end_time * self.fps))
                
                # ä¸¥æ ¼è¾¹ç•Œæ£€æŸ¥ï¼šé˜²æ­¢è®¡ç®—å‡ºçš„ç´¢å¼•è¶…å‡ºç‰¹å¾é•¿åº¦
                if frame_idx < target_frames:
                    y_true[frame_idx] = 1.0
                elif frame_idx == target_frames: # å®¹é”™å¤„ç†
                    y_true[target_frames - 1] = 1.0
                    
            return y_true
        except Exception as e:
            # å¦‚æœ JSON æŸåï¼Œè¿”å›å…¨ 0ï¼Œé˜²æ­¢è®­ç»ƒä¸­æ–­
            return torch.zeros(target_frames, dtype=torch.float32)

class TICSDataset(Dataset):
    def __init__(self, csv_path: str, sample_rate: int = 16000, xlmr_path="/mnt/facebook/xlm-roberta-large", augmentor=None, stage=1):
        self.stage = stage
        self.sample_rate = sample_rate
        
        # 1. æ›´åŠ å¥å£®çš„ CSV åŠ è½½
        print(f"ğŸ” æ­£åœ¨åŠ è½½ CSV æ–‡ä»¶: {csv_path}")
        # å¦‚æœä½ çš„ CSV ç¡®å®æ²¡æœ‰è¡¨å¤´ï¼Œç”¨ header=Noneï¼›å¦‚æœæœ‰ï¼Œç”¨ header=0
        df = pd.read_csv(csv_path, header=None) 
        
        # 2. æ ¸å¿ƒï¼šè¿‡æ»¤æ‰éè·¯å¾„çš„æ— æ•ˆè¡Œï¼ˆæ¯”å¦‚è¡¨å¤´æ–‡å­—ï¼‰
        # åªæœ‰å½“ç¬¬ä¸€åˆ—åŒ…å« '/' (è·¯å¾„ç‰¹å¾) ä¸”ä¸ä¸ºç©ºæ—¶æ‰ä¿ç•™
        valid_mask = df.iloc[:, 0].str.contains('/', na=False)
        df = df[valid_mask]
        
        self.audio_files = df.iloc[:, 0].tolist()
        self.json_files = df.iloc[:, 1].tolist() 
        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæœ‰æ•ˆæ¡æ•°: {len(self.audio_files)}")

        # ç»„ä»¶åˆå§‹åŒ–
        self.tokenizer = XLMRobertaTokenizer.from_pretrained(xlmr_path)
        self.augmentor = augmentor if augmentor else TicsAugmentation(mode='none')
        self.label_gen = BoundaryLabelGenerator(fps=50)

    def __len__(self):
        return len(self.audio_files)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        try:
            #print(f"DEBUG: [Rank {torch.distributed.get_rank()}] Loading Index: {idx}")
            audio_path = self.audio_files[idx]
            json_path = self.json_files[idx]

            # --- å…³é”®è°ƒè¯•ç‚¹ï¼šå¦‚æœè¿˜æ˜¯æŠ¥é”™ï¼Œè¿™é‡Œä¼šæ‰“å°å‡ºå…·ä½“çš„è·¯å¾„å†…å®¹ ---
            if not os.path.exists(json_path):
                # é’ˆå¯¹ 400 ä¸‡æ•°æ®ï¼šè·³è¿‡æŸåæ ·æœ¬ï¼Œé€’å½’å–ä¸‹ä¸€ä¸ª
                print(f"âš ï¸ æ‰¾ä¸åˆ° JSON.......: {json_path}ï¼Œå°è¯•ä¸‹ä¸€æ¡...")
                return self.__getitem__((idx + 1) % len(self))

            # 1. åŠ è½½å…ƒæ•°æ®
            with open(json_path, 'r') as f:
                meta = json.load(f)

            # 2. åŠ è½½éŸ³é¢‘
            if not os.path.exists(audio_path):
                return self.__getitem__((idx + 1) % len(self))
                
            waveform, sr = torchaudio.load(audio_path)
            
            # é‡é‡‡æ ·å¤„ç† (å¦‚æœç£ç›˜æ–‡ä»¶ä¸æ˜¯ 16k)
            if sr != self.sample_rate:
                resampler = torchaudio.transforms.Resample(sr, self.sample_rate)
                waveform = resampler(waveform)

            # å¼ºåˆ¶å•å£°é“
            if waveform.shape[0] > 1:
                waveform = waveform.mean(dim=0, keepdim=True)
                
            # 3. è®¡ç®— HuBERT å¸§æ•°å¹¶è¿‡æ»¤è¶…çŸ­éŸ³é¢‘
            target_T = waveform.shape[1] // 320
            if target_T <= 1: 
                return self.__getitem__((idx + 1) % len(self))

            # 4. ç”Ÿæˆæ ‡ç­¾ (ä¼ å…¥ json_path æˆ– metaï¼Œå–å†³äºä½  Generator çš„å®ç°)
            y_true = self.label_gen.generate(json_path, target_T)

            # 5. ç”Ÿæˆå¢å¼ºè§†å›¾
            view1 = self.augmentor(waveform, is_view2=False)
            view2 = self.augmentor(waveform, is_view2=True)

            if self.stage == 2:
                text = meta.get('text', "")
                encoded_text = self.tokenizer(
                    text,
                    padding='max_length',
                    truncation=True,
                    max_length=128,
                    return_tensors='pt'
                )
                return {
                    "view1": view1.squeeze(0),
                    "y_true": y_true,
                    "text_ids": encoded_text['input_ids'].squeeze(0),
                    "text_mask": encoded_text['attention_mask'].squeeze(0)
                }

            return {
                "view1": view1.squeeze(0),
                "view2": view2.squeeze(0),
                "y_true": y_true
            }

        except Exception as e:
            # ä¸‡èƒ½æ•è·ï¼Œç¡®ä¿ 400 ä¸‡è®­ç»ƒä¸ä¼šå› ä¸ºæŸä¸€ä¸ª json æ ¼å¼é”™è¯¯è€Œä¸­æ–­
            # print(f"âŒ ç´¢å¼• {idx} åŠ è½½å´©æºƒ: {str(e)}")
            return self.__getitem__((idx + 1) % len(self))
        

def tics_collate_fn(batch):
    """
    å…¼å®¹ Stage I å’Œ Stage II çš„åŠ¨æ€ Padding å‡½æ•°
    """
    # 1. åŸºç¡€é¡¹æå– (æ‰€æœ‰é˜¶æ®µå…±æœ‰)
    view1_list = [item['view1'] for item in batch]
    y_true_list = [item['y_true'] for item in batch]
    
    # å¯¹éŸ³é¢‘å’Œè¾¹ç•Œæ ‡ç­¾è¿›è¡Œ Padding
    padded_view1 = pad_sequence(view1_list, batch_first=True, padding_value=0.0)
    padded_y_true = pad_sequence(y_true_list, batch_first=True, padding_value=0.0)
    
    # ç”ŸæˆéŸ³é¢‘æ©ç  y_mask (ç”¨äº Boundary Loss æ’é™¤ padding éƒ¨åˆ†)
    # y_true å½¢çŠ¶ä¸º (B, T)ï¼Œy_mask åœ¨æœ‰æ•ˆé•¿åº¦ä¸º 1ï¼Œpadding ä¸º 0
    lengths = [len(y) for y in y_true_list]
    max_len = max(lengths)
    y_mask = torch.zeros((len(batch), max_len), dtype=torch.float32)
    for i, l in enumerate(lengths):
        y_mask[i, :l] = 1.0

    # æ„é€ åŸºç¡€è¿”å›å­—å…¸
    output = {
        "view1": padded_view1,
        "y_true": padded_y_true,
        "y_mask": y_mask
    }

    # 2. Stage I ç‰¹æœ‰é¡¹ï¼šå¤„ç† view2 (å¯¹æ¯”è§†å›¾)
    if 'view2' in batch[0]:
        view2_list = [item['view2'] for item in batch]
        output["view2"] = pad_sequence(view2_list, batch_first=True, padding_value=0.0)

    # 3. Stage II ç‰¹æœ‰é¡¹ï¼šå¤„ç†æ–‡æœ¬ Token
    if 'text_ids' in batch[0]:
        text_ids_list = [item['text_ids'] for item in batch]
        text_mask_list = [item['text_mask'] for item in batch]
        
        # æ–‡æœ¬é€šå¸¸åœ¨ Dataset é‡Œå·²ç»å›ºå®šäº† max_lengthï¼Œä½†ä¿é™©èµ·è§è¿™é‡Œå†åšä¸€æ¬¡ pad
        output["text_ids"] = pad_sequence(text_ids_list, batch_first=True, padding_value=1) # XLM-R pad ID é€šå¸¸æ˜¯ 1ï¼Œè¯·æ ¹æ® tokenizer ç¡®è®¤
        output["text_mask"] = pad_sequence(text_mask_list, batch_first=True, padding_value=0.0)

    return output



def get_tics_dataloader(csv_path: str, batch_size: int, num_workers: int):
    dataset = TICSDataset(csv_path)
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=tics_collate_fn,
        pin_memory=True
    )