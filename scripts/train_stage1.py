import argparse
import deepspeed
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from moco_tics.model import TICS_MoCo
from moco_tics.data_loader import TICSDataset, tics_collate_fn
from tqdm import tqdm
import os
from moco_tics.TicsAugmentation import TicsAugmentation

# ç¡®ä¿ Y_true å’Œ P_score çš„é•¿åº¦å¯¹é½
class BoundaryLoss(nn.Module):
    def __init__(self, pos_weight=15.0):
        super().__init__()
        self.pos_weight = pos_weight

    def forward(self, P_score, Y_true, mask=None):
        # ç¡®ä¿æ—¶é—´æ­¥å¯¹é½
        min_t = min(P_score.size(1), Y_true.size(1))
        P_score = P_score[:, :min_t]
        Y_true = Y_true[:, :min_t].float()
        Y_true = Y_true.to(P_score.dtype)
        if mask is not None:
            mask = mask.to(P_score.dtype)
        # BCE æŸå¤±
        loss = F.binary_cross_entropy(P_score, Y_true, reduction='none')
        
        # ç±»åˆ«ä¸å¹³è¡¡å¤„ç† (è¾¹ç•Œç‚¹éå¸¸ç¨€ç–ï¼Œæ‰€ä»¥ pos_weight è®¾ä¸º 15)
        if self.pos_weight != 1.0:
            weight = 1.0 + Y_true * (self.pos_weight - 1.0)
            loss = loss * weight
            
        # æ©ç å¤„ç†ï¼šåªè®¡ç®—éŸ³é¢‘å®é™…é•¿åº¦éƒ¨åˆ†çš„æŸå¤±
        if mask is not None:
            mask = mask[:, :min_t].float()
            return (loss * mask).sum() / (mask.sum() + 1e-6)
        return loss.mean()

class TICSContrastiveLoss(nn.Module):
    def __init__(self, temperature=0.1):
        super().__init__()
        self.temperature = temperature

    def forward(self, outputs):
        # è®¡ç®— q1->k2 å’Œ q2->k1 çš„å¯¹ç§°æŸå¤±
        loss_a = self._compute_segment_loss(outputs['q1'], outputs['k2'], outputs['mask1'])
        loss_b = self._compute_segment_loss(outputs['q2'], outputs['k1'], outputs['mask2'])
        return (loss_a + loss_b) / 2

    def _compute_segment_loss(self, q, k, mask):
        """
        q, k: (S, B, D)
        mask: (B, S) -> True è¡¨ç¤ºæ˜¯ padding
        """
        # 1. è½¬æ¢ç»´åº¦ä¸º (B, S, D) æ–¹ä¾¿ä¸ mask å¯¹åº”
        q = q.transpose(0, 1) 
        k = k.transpose(0, 1)
        
        # 2. æˆ‘ä»¬ä½¿ç”¨ Mean Pooling å¾—åˆ°å¥å­çº§è¡¨ç¤ºè¿›è¡Œå¯¹æ¯” (Stage 1 æ¨èåšæ³•)
        # æˆ–è€…å¦‚æœä½ æƒ³åšæ›´ç»†ç²’åº¦çš„ç‰‡æ®µå¯¹æ¯”ï¼Œå¯ä»¥ä½¿ç”¨ mask è¿‡æ»¤
        # è¿™é‡Œé‡‡ç”¨å¸¦ Mask çš„å¹³å‡æ± åŒ–ï¼Œæ¯”å•çº¯çš„ .mean(dim=0) æ›´å‡†ç¡®
        fill_mask = mask.unsqueeze(-1).expand_as(q) # (B, S, D)
        q_masked = q.clone().masked_fill(fill_mask, 0.0)
        k_masked = k.clone().masked_fill(fill_mask, 0.0)
        
        valid_counts = (~mask).sum(dim=1, keepdim=True).clamp(min=1) # æ¯ä¸ª batch æœ‰å¤šå°‘æœ‰æ•ˆç‰‡æ®µ
        q_avg = q_masked.sum(dim=1) / valid_counts
        k_avg = k_masked.sum(dim=1) / valid_counts
        
        # 3. æ ‡å‡† MoCo å¯¹æ¯”è®¡ç®— (é’ˆå¯¹ Batch)
        logits = torch.matmul(q_avg, k_avg.T) / self.temperature
        labels = torch.arange(q_avg.shape[0], device=q.device)
        return F.cross_entropy(logits, labels)


def parse_args():
    parser = argparse.ArgumentParser(description="TICS Stage I Training")
    parser.add_argument('--local_rank', type=int, default=-1)
    parser.add_argument('--csv_path', type=str, required=True)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--lambda_sup', type=float, default=1.0)
    parser.add_argument('--lambda_moco', type=float, default=0.5)
    parser.add_argument('--aug_mode', type=str, default="baseline")
    parser = deepspeed.add_config_arguments(parser)
    return parser.parse_args()

def main():
    args = parse_args()
    
    # 1. è·¯å¾„ä¸é…ç½®å‡†å¤‡
    checkpoint_dir = "checkpoints_stage1"
    best_model_dir = os.path.join(checkpoint_dir, "best")
    if args.local_rank <= 0:
        os.makedirs(checkpoint_dir, exist_ok=True)

    TEACHER_CONFIG = {
        'input_dim': 768, 
        'segment_dim': 1024, 
        'num_layers': 12,
    }

    augmentor = TicsAugmentation(mode=args.aug_mode)

    # 2. æ¨¡å‹åˆå§‹åŒ–
    # TICS_MoCo å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç† encoder_k çš„åˆå§‹åŒ–å’Œ load_pretrained_weights
    model = TICS_MoCo(
        backbone_path="/mnt/facebook/hubert-base-ls960", 
        teacher_config=TEACHER_CONFIG
    )

    # 3. æ•°æ®å‡†å¤‡
    train_dataset = TICSDataset(csv_path=args.csv_path, augmentor=augmentor, stage=1)

    #print("âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆï¼Œé•¿åº¦:", len(train_dataset))
    #test_loader = DataLoader(train_dataset, batch_size=1, collate_fn=tics_collate_fn, num_workers=0)
    #test_batch = next(iter(test_loader))
    #print("âœ… å•batchåŠ è½½æˆåŠŸï¼Keys:", list(test_batch.keys()))
    #print("view1 shape:", test_batch["view1"].shape if "view1" in test_batch else "æ— view1")
    #del test_loader, test_batch
    #print("âœ… æ•°æ®é›†æµ‹è¯•é€šè¿‡")
    # ===== ç»“æŸæ·»åŠ  =====
    
    # 4. DeepSpeed åˆå§‹åŒ–
    # model_engine å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒã€FP16 æ··åˆç²¾åº¦å’Œä¼˜åŒ–å™¨æ›´æ–°
    model_engine, optimizer, trainloader, _ = deepspeed.initialize(
        args=args,
        model=model,
        model_parameters=model.parameters(),
        training_data=train_dataset,
        collate_fn=tics_collate_fn,
    )

    # 5. æŸå¤±å‡½æ•°å®šä¹‰
    contrastive_criterion = TICSContrastiveLoss(temperature=0.1).to(model_engine.device)
    boundary_criterion = BoundaryLoss(pos_weight=15.0).to(model_engine.device)

    # 6. è®­ç»ƒç›‘æ§å˜é‡
    best_loss = float('inf')
    
    # --- è®­ç»ƒå¾ªç¯ ---
    for epoch in range(args.epochs):
        model_engine.train()
        epoch_moco_loss = 0.0
        epoch_sup_loss = 0.0
        epoch_total_loss = 0.0
        
        # ä½¿ç”¨ tqdm åœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦
        pbar = tqdm(trainloader, desc=f"Epoch {epoch}", disable=(args.local_rank > 0))
        
        for step, batch in enumerate(pbar):
            # è·å–æ•°æ®å¹¶è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„åŠç²¾åº¦
            view1 = batch["view1"].to(model_engine.device).half()
            view2 = batch["view2"].to(model_engine.device).half()
            y_true = batch["y_true"].to(model_engine.device)
            y_mask = batch.get("y_mask", torch.ones_like(y_true)).to(model_engine.device)

            # --- Forward ---
            outputs = model_engine(view1, view2)

            # --- Loss è®¡ç®— ---
            # 1. è¾¹ç•Œå‘ç°æŸå¤± (ç›‘ç£å­¦ä¹ )
            loss_sup = boundary_criterion(outputs["P_score"], y_true, mask=y_mask)
            
            # 2. è¯­ä¹‰å¯¹æ¯”æŸå¤± (MoCo è‡ªç›‘ç£)
            loss_moco = contrastive_criterion(outputs)

            # æ€»æŸå¤±åŠ æƒ
            total_loss = args.lambda_moco * loss_moco + args.lambda_sup * loss_sup

            # --- Backward & Optimize ---
            model_engine.backward(total_loss)
            model_engine.step()

            # ç´¯ç§¯ç»Ÿè®¡é‡
            epoch_total_loss += total_loss.item()
            epoch_moco_loss += loss_moco.item()
            epoch_sup_loss += loss_sup.item()

            # --- å®æ—¶ç›‘æ§é€»è¾‘ ---
            if step % 10 == 0 and args.local_rank <= 0:
                p_avg = outputs["P_score"].mean().item()
                # æ£€æŸ¥ P_avg æ˜¯å¦å¼‚å¸¸ï¼ˆä¾‹å¦‚å…¨éƒ¨è¶‹å‘ 0 æˆ– 1ï¼‰ï¼Œé¢„é˜²æ¨¡å‹å´©å¡Œ
                status_msg = "OK" if 0.01 < p_avg < 0.5 else "WARNING: COLLAPSE?"
                
                pbar.set_postfix({
                    "Loss": f"{total_loss.item():.4f}",
                    "MoCo": f"{loss_moco.item():.4f}",
                    "P_avg": f"{p_avg:.3f}",
                    "Status": status_msg
                })

        # --- Epoch ç»“æŸï¼šæ¨¡å‹ä¿å­˜ä¸æœ€ä¼˜é€»è¾‘ ---
        avg_loss = epoch_total_loss / len(trainloader)
        
        if args.local_rank <= 0:
            print(f"\n>> Epoch {epoch} Finished. Average Loss: {avg_loss:.4f}")
            
            # 1. ä¿å­˜æœ€æ–°çš„ Checkpoint (DeepSpeed æ ¼å¼)
            model_engine.save_checkpoint(checkpoint_dir, tag=f"epoch_{epoch}")
            
            # 2. æœ€ä¼˜æ¨¡å‹æ›¿ä»£é€»è¾‘
            if avg_loss < best_loss:
                print(f"ğŸ† New Best Loss: {avg_loss:.4f} (Previous: {best_loss:.4f})")
                best_loss = avg_loss
                
                # ä¿å­˜ DeepSpeed æ ¼å¼çš„æœ€ä¼˜æ¨¡å‹
                model_engine.save_checkpoint(checkpoint_dir, tag="best")
                
                # åŒæ—¶é¢å¤–ä¿å­˜ä¸€ä»½æ ‡å‡†çš„ PyTorch æƒé‡ï¼Œæ–¹ä¾¿ Stage 2 ç›´æ¥è°ƒç”¨
                best_pt_path = os.path.join(checkpoint_dir, "tics_stage1_best.pt")
                torch.save(model.state_dict(), best_pt_path)
                print(f"âœ… Best weights synced to {best_pt_path}")

    print("Training Stage 1 completed.")

if __name__ == "__main__":
    main()