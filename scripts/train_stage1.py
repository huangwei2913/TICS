import argparse
import deepspeed
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from moco_tics.model import TICS_MoCo
from moco_tics.data_loader import TICSDataset, tics_collate_fn
from tqdm import tqdm
import os
from moco_tics.TicsAugmentation import TicsAugmentation
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler


# ç¡®ä¿ Y_true å’Œ P_score çš„é•¿åº¦å¯¹é½
class BoundaryLoss(nn.Module):
    def __init__(self, pos_weight=15.0):
        super().__init__()
        self.pos_weight = pos_weight

    def forward(self, P_score, Y_true, mask=None):
        # ç¡®ä¿æ—¶é—´æ­¥å¯¹é½
        min_t = min(P_score.size(1), Y_true.size(1))
        P_score = P_score[:, :min_t]
        Y_true = Y_true[:, :min_t].float()
        Y_true = Y_true.to(P_score.dtype)
        if mask is not None:
            mask = mask.to(P_score.dtype)
        # BCE æŸå¤±
        loss = F.binary_cross_entropy(P_score, Y_true, reduction='none')
        
        # ç±»åˆ«ä¸å¹³è¡¡å¤„ç† (è¾¹ç•Œç‚¹éå¸¸ç¨€ç–ï¼Œæ‰€ä»¥ pos_weight è®¾ä¸º 15)
        if self.pos_weight != 1.0:
            weight = 1.0 + Y_true * (self.pos_weight - 1.0)
            loss = loss * weight
            
        # æ©ç å¤„ç†ï¼šåªè®¡ç®—éŸ³é¢‘å®é™…é•¿åº¦éƒ¨åˆ†çš„æŸå¤±
        if mask is not None:
            mask = mask[:, :min_t].float()
            return (loss * mask).sum() / (mask.sum() + 1e-6)
        return loss.mean()

class TICSContrastiveLoss(nn.Module):
    def __init__(self, temperature=0.1):
        super().__init__()
        self.temperature = temperature

    def forward(self, outputs):
        # è®¡ç®— q1->k2 å’Œ q2->k1 çš„å¯¹ç§°æŸå¤±
        loss_a = self._compute_segment_loss(outputs['q1'], outputs['k2'], outputs['mask1'])
        loss_b = self._compute_segment_loss(outputs['q2'], outputs['k1'], outputs['mask2'])
        return (loss_a + loss_b) / 2

    def _compute_segment_loss(self, q, k, mask):
            """
            é«˜æ€§èƒ½ã€é«˜å¼ºåº¦ç‰ˆæœ¬ï¼š
            1. ä¿®å¤é•¿åº¦ä¸åŒ¹é… Bug (s_min)
            2. å®ç°åˆ†æ®µçº§å¯¹æ¯”å­¦ä¹  (Flatten Contrast)
            """
            # [ç»´åº¦è½¬æ¢] ä» (S, B, D) å˜ä¸º (B, S, D)
            q, k = q.transpose(0, 1), k.transpose(0, 1)
            
            # [Bug ä¿®å¤] å¼ºåˆ¶å¯¹é½åºåˆ—é•¿åº¦ï¼Œé˜²æ­¢ 441 vs 440 æŠ¥é”™
            s_min = min(q.size(1), k.size(1), mask.size(1))
            q, k, mask = q[:, :s_min, :], k[:, :s_min, :], mask[:, :s_min]

            # [ä¸Šå¼ºåº¦æ ¸å¿ƒ] å±•å¹³æ‰€æœ‰ Batch é‡Œçš„æœ‰æ•ˆç‰‡æ®µ
            # valid_indices æ˜¯ä¸€ä¸ª (B, S) çš„å¸ƒå°”çŸ©é˜µ
            valid_indices = ~mask 
            
            # æå–æœ‰æ•ˆç‰‡æ®µï¼šç»“æœç»´åº¦ä¸º (N_total_valid_segments, D)
            # è¿™ä¸€æ­¥ä¼šè‡ªåŠ¨æŠŠ Batch ç»´åº¦å’Œ Seq ç»´åº¦å‹å¹³ï¼Œåªç•™ä¸‹çœŸå®çš„è¯­éŸ³å‘é‡
            q_valid = q[valid_indices] 
            k_valid = k[valid_indices]

            # å®‰å…¨æ£€æŸ¥
            if q_valid.size(0) == 0:
                return torch.tensor(0.0, device=q.device, requires_grad=True)

            # [è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ] (N_total, D) @ (D, N_total) -> (N_total, N_total)
            # æ¯ä¸ªç‰‡æ®µéƒ½è¦å’Œ Batch å†…æ‰€æœ‰å…¶ä»–ç‰‡æ®µåšå¯¹æ¯”
            logits = torch.matmul(q_valid, k_valid.T) / self.temperature
            
            # [æ„é€ æ ‡ç­¾] å¯¹è§’çº¿ä½ç½®å³ä¸ºæ­£æ ·æœ¬ï¼ˆå¯¹åº”çš„ç‰‡æ®µï¼‰
            labels = torch.arange(q_valid.size(0), device=q.device)

            # è¿”å› CrossEntropy Loss
            return F.cross_entropy(logits, labels)
        




def parse_args():
    parser = argparse.ArgumentParser(description="TICS Stage I Training")
    parser.add_argument('--local_rank', type=int, default=-1)
    parser.add_argument('--csv_path', type=str, required=True)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--lambda_sup', type=float, default=1.0)
    parser.add_argument('--lambda_moco', type=float, default=0.5)
    parser.add_argument('--aug_mode', type=str, default="shuffle")
    parser = deepspeed.add_config_arguments(parser)
    return parser.parse_args()

def main():
    args = parse_args()
    
    # 1. è·¯å¾„ä¸é…ç½®å‡†å¤‡
    checkpoint_dir = "checkpoints_stage1"
    best_model_dir = os.path.join(checkpoint_dir, "best")
    if args.local_rank <= 0:
        os.makedirs(checkpoint_dir, exist_ok=True)

    TEACHER_CONFIG = {
        'input_dim': 768, 
        'segment_dim': 1024, 
        'num_layers': 12,
    }

    augmentor = TicsAugmentation(mode=args.aug_mode)

    # 2. æ¨¡å‹åˆå§‹åŒ–
    # TICS_MoCo å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç† encoder_k çš„åˆå§‹åŒ–å’Œ load_pretrained_weights
    model = TICS_MoCo(
        backbone_path="/mnt/facebook/hubert-base-ls960", 
        teacher_config=TEACHER_CONFIG
    )

    for param in model.backbone.parameters():
        param.requires_grad = False

    # 3. æ•°æ®å‡†å¤‡
    train_dataset = TICSDataset(csv_path=args.csv_path, augmentor=augmentor, stage=1)

    # 4. DeepSpeed åˆå§‹åŒ–
    # model_engine å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒã€FP16 æ··åˆç²¾åº¦å’Œä¼˜åŒ–å™¨æ›´æ–°
    model_engine, optimizer, trainloader, _ = deepspeed.initialize(
        args=args,
        model=model,
        model_parameters=model.parameters(),
        training_data=train_dataset,  # âœ… æ¢å¤è¿™ä¸ªï¼
        collate_fn=tics_collate_fn,
    )
    

    # 5. æŸå¤±å‡½æ•°å®šä¹‰
    contrastive_criterion = TICSContrastiveLoss(temperature=0.1).to(model_engine.device)
    boundary_criterion = BoundaryLoss(pos_weight=15.0).to(model_engine.device)

    # 6. è®­ç»ƒç›‘æ§å˜é‡
    best_loss = float('inf')
    
    # --- è®­ç»ƒå¾ªç¯ ---
    for epoch in range(args.epochs):
        model_engine.train()
        epoch_moco_loss = 0.0
        epoch_sup_loss = 0.0
        epoch_total_loss = 0.0
        
        # ä½¿ç”¨ tqdm åœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦
        pbar = tqdm(trainloader, desc=f"Epoch {epoch}", disable=(args.local_rank > 0))
        
        for step, batch in enumerate(pbar):
            # è·å–æ•°æ®å¹¶è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„åŠç²¾åº¦
            view1 = batch["view1"].to(model_engine.device).half()
            view2 = batch["view2"].to(model_engine.device).half()
            y_true = batch["y_true"].to(model_engine.device)
            y_mask = batch.get("y_mask", torch.ones_like(y_true)).to(model_engine.device)

            # --- Forward ---
            #outputs = model_engine(view1, view2)
            outputs = model_engine(view1, view2, aug_mode=args.aug_mode)
            # --- Loss è®¡ç®— ---
            # 1. è¾¹ç•Œå‘ç°æŸå¤± (ç›‘ç£å­¦ä¹ )
            loss_sup = boundary_criterion(outputs["P_score"], y_true, mask=y_mask)
            
            # 2. è¯­ä¹‰å¯¹æ¯”æŸå¤± (MoCo è‡ªç›‘ç£)
            loss_moco = contrastive_criterion(outputs)

            # æ€»æŸå¤±åŠ æƒ
            total_loss = args.lambda_moco * loss_moco + args.lambda_sup * loss_sup

            # --- Backward & Optimize ---
            model_engine.backward(total_loss)
            model_engine.step()

            # ç´¯ç§¯ç»Ÿè®¡é‡
            epoch_total_loss += total_loss.item()
            epoch_moco_loss += loss_moco.item()
            epoch_sup_loss += loss_sup.item()

            # --- å®æ—¶ç›‘æ§é€»è¾‘ ---
            if step % 10 == 0 and args.local_rank <= 0:
                p_avg = outputs["P_score"].mean().item()
                # æ£€æŸ¥ P_avg æ˜¯å¦å¼‚å¸¸ï¼ˆä¾‹å¦‚å…¨éƒ¨è¶‹å‘ 0 æˆ– 1ï¼‰ï¼Œé¢„é˜²æ¨¡å‹å´©å¡Œ
                status_msg = "OK" if 0.01 < p_avg < 0.5 else "WARNING: COLLAPSE?"
                
                pbar.set_postfix({
                    "Loss": f"{total_loss.item():.4f}",
                    "MoCo": f"{loss_moco.item():.4f}",
                    "P_avg": f"{p_avg:.3f}",
                    "Status": status_msg
                })

        # --- Epoch ç»“æŸï¼šæ¨¡å‹ä¿å­˜ä¸æœ€ä¼˜é€»è¾‘ ---
        avg_loss = epoch_total_loss / len(trainloader)
        
        if args.local_rank <= 0:
            print(f"\n>> Epoch {epoch} Finished. Average Loss: {avg_loss:.4f}")
            
            # 1. ä¿å­˜æœ€æ–°çš„ Checkpoint (DeepSpeed æ ¼å¼)
            model_engine.save_checkpoint(checkpoint_dir, tag=f"epoch_{epoch}")
            
            # 2. æœ€ä¼˜æ¨¡å‹æ›¿ä»£é€»è¾‘
            if avg_loss < best_loss:
                print(f"ğŸ† New Best Loss: {avg_loss:.4f} (Previous: {best_loss:.4f})")
                best_loss = avg_loss
                
                # ä¿å­˜ DeepSpeed æ ¼å¼çš„æœ€ä¼˜æ¨¡å‹
                model_engine.save_checkpoint(checkpoint_dir, tag="best")
                
                # åŒæ—¶é¢å¤–ä¿å­˜ä¸€ä»½æ ‡å‡†çš„ PyTorch æƒé‡ï¼Œæ–¹ä¾¿ Stage 2 ç›´æ¥è°ƒç”¨
                best_pt_path = os.path.join(checkpoint_dir, "tics_stage1_best.pt")
                torch.save(model.state_dict(), best_pt_path)
                print(f"âœ… Best weights synced to {best_pt_path}")

    print("Training Stage 1 completed.")

if __name__ == "__main__":
    main()